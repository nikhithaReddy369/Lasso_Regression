---
title: "LASSO Regression Report - Data Science Capstone Project"
author: "Nikhitha Amireddy, Ishrath Jahan, Sai Kumar Miryala, Muhammad Usman Aslam"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

## Introduction

The introduction of the Least Absolute Shrinkage and Selection Operator (LASSO) regression by Tibshirani in 1996[@Tibshirani] heralded a paradigm shift in statistical analysis and predictive modeling, offering an elegant solution to the perennial challenges of large, complex datasets analysis. This methodological innovation, characterized by its penalty on the sum of the absolute values of regression coefficients, simplifies model complexity and enhances interpretability while mitigating the risk of overfitting. As such, LASSO regression has been embraced across a spectrum of scientific fields, from public health and economic forecasting to environmental studies, establishing itself as an indispensable tool in the arsenal of data scientists. Its ability to extract meaningful insights from high-dimensional datasets, underscored by foundational work such as Efron et al.’s (2004)[@annalsofstatistics] development of Least Angle Regression, places LASSO regression at the forefront of the analytical revolution, facilitating a nuanced understanding of variables influencing critical outcomes in varied domains.

This body of research, enriched by the pioneering contributions of Tibshirani (1996)[@Tibshirani] and expanded by subsequent investigations like those of Muthukrishnan and Rohini (2016)[@7887916], explores the intricate dynamics of socioeconomic, educational, and demographic variables through the lens of LASSO regression. By leveraging comprehensive datasets, these studies aim to elucidate the complex dynamics affecting wage disparities, educational attainment, and labor market performance, demonstrating LASSO regression’s unparalleled proficiency in managing and interpreting high-dimensional data. The work of Sohaee and Bohluli (2024a; 2024b) [@safety10010011],[@38166942] further exemplifies LASSO’s capacity to unearth underlying factors affecting societal phenomena, employing it not merely as a computational tool but as a window into the multifaceted relationships that shape our world.


## Literature Review

The introduction of LASSO regression has significantly improved the precision and interpretability of predictive models, particularly for high-dimensional datasets where traditional methods falter due to overfitting and multicollinearity. Tibshirani’s (1996)[@RegressionShrinkage] groundbreaking work laid the foundation for a new era in statistical modeling, providing a robust framework for variable selection and regularization that has since been applied across diverse research domains. The versatility and efficiency of LASSO regression, further elucidated by Efron et al. (2004)[@annalsofstatistics] through the concept of Least Angle Regression, have facilitated its widespread adoption and integration into various fields of study.

In public health, LASSO regression has proven invaluable in identifying key socioeconomic and demographic determinants of health outcomes and safety measures. Studies by Sohaee and Bohluli (2024a; 2024b) [@safety10010011],[@38166942]have utilized LASSO to pinpoint influential variables impacting public health and safety, offering insights critical for policy development and strategic interventions. Similarly, in the economic sector, research has leveraged LASSO to dissect the complex interplay of factors driving economic growth and labor market dynamics, with investigations like those by Chunli Zhoua & X. L. (2022)[@ZHOU20221055] revealing insights into the drivers of economic resilience and advancement.

Environmental and operational research domains have also benefited from the predictive capabilities of LASSO regression. The work by Wang et al. (2017)[@WANG2018817] on forecasting ship fuel consumption exemplifies the algorithm's capacity to enhance predictive accuracy and operational efficiency in complex environmental contexts. Furthermore, the contribution by Muthukrishnan & Rohini (2016)[@7887916] has expanded the scope of LASSO’s utility into the realm of machine learning, showcasing its effectiveness in feature selection and model simplification.

Recent advancements in LASSO regression have focused on addressing the limitations inherent in its application, such as the challenge of tuning parameter selection and the interpretation of results in the presence of highly correlated predictors. This ongoing research effort aims to refine and adapt LASSO algorithms for enhanced flexibility and broader applicability. Future research directions also include the exploration of LASSO’s integration with cutting-edge machine learning techniques and its application to emerging research areas. Such developments promise not only to extend the utility of LASSO regression but also to contribute significantly to the evolution of statistical analysis and predictive modeling methodologies.

Moreover, the interdisciplinary applications of LASSO regression underscore its transformative impact on empirical research. By facilitating the analysis of complex datasets in fields ranging from genomics to social sciences, LASSO regression has become a critical tool for researchers seeking to model relationships within data where traditional regression models fall short. Its role in advancing the understanding of genetic markers, socioeconomic patterns, and environmental trends exemplifies the broadening scope of statistical modeling techniques in the modern research landscape. As we move forward, the adaptability and precision of LASSO regression will continue to play a pivotal role in uncovering new insights and fostering innovation across various scientific disciplines.



## Methods

The common non-parametric regression model is
$Y_i = m(X_i) + \varepsilon_i$, where $Y_i$ can be defined as the sum of
the regression function value $m(x)$ for $X_i$. Here $m(x)$ is unknown
and $\varepsilon_i$ some errors. With the help of this definition, we
can create the estimation for local averaging i.e. $m(x)$ can be
estimated with the product of $Y_i$ average and $X_i$ is near to $x$. In
other words, this means that we are discovering the line through the
data points with the help of surrounding data points. The estimation
formula is printed below [@R-base]:

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$ $W_n(x)$ is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if $X_i$ is far from $x$.

Another equation:

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$

## Analysis and Results

### Data and Visualization

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{r, warning=FALSE, echo=TRUE}
# Load Data
kable(head(murders))

ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Statistical Modeling

```{r}

```

### Conclusion

## References


[1]	Chunli Zhoua, X. L. (2022). "Influencing factors of the high-quality economic development in China based on LASSO model." Energy Reports, 8, 1055–1065.
[2]	Efron, B., Hastie, T., Johnstone, I., & Tibshirani, R. (2004). "Least angle regression." Annals of Statistics, 32(2), 407-499.
[3]	Sohaee, R., & Bohluli, M. (2024a). "Effect of Neighborhood and Individual-Level Socioeconomic Factors on Breast Cancer Screening Adherence." Journal of Public Health.
[4]	Sohaee, R., & Bohluli, M. (2024b). "Nonlinear Analysis of the Effects of Socioeconomic, Demographic, and Technological Factors on the Number of Fatal Traffic Accidents." Safety, 10(1).
[5]	Tibshirani, R. (1996). "Regression shrinkage and selection via the lasso." Journal of the Royal Statistical Society: Series B (Methodological), 58(1), 267-288.
[6]	Wang, S. J., et al. (2017). "Predicting ship fuel consumption based on LASSO regression." Elsevier, 1361-9209.
[7]Muthukrishnan, R., & Rohini, R. (2016). "LASSO: A feature selection technique in predictive modeling for machine learning." 2016 IEEE International Conference on Advances in Computer Applications (ICACA), Coimbatore, India, pp. 18-20, doi: 10.1109/ICACA.2016.7887916.
